{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMlzP8XmONuhJWLlHDWUzC5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9UkWzJ2iIFC3"},"outputs":[],"source":["# ResNet model\n","from ca_utils import ResNet, BasicBlock\n","model = ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=10)  # change num_classes if needed, this is an example\n","\n","# Dataset\n","from torchvision import transforms, datasets\n","\n","import os\n","if not os.path.exists('EXCV10.zip'):\n","    !unzip -q EXCV10.zip\n","\n","# Vanilla image transform\n","image_transform = transforms.Compose([\n","    transforms.RandomCrop(32, padding=8, padding_mode='reflect'),               # Random Position Crop\n","    transforms.RandomHorizontalFlip(),                  # right and left flip\n","    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n","    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n","                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n","])\n","\n","# Dataset\n","import torchvision\n","train_data = torchvision.datasets.ImageFolder('train/', transform=image_transform)\n","\n","# Data loader\n","from torch.utils.data import DataLoader\n","train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)"]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","## create model and optimizer\n","learning_rate = 0.0001\n","weight_decay = 0.0005\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model = model.to(device)\n","\n","# make the parameters trainable\n","for param in model.parameters():\n","    param.requires_grad = True\n","# define optimizer\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","from tqdm import tqdm_notebook as tqdm\n","\n","# Train CNN\n","def train_cnn(model, train_loader):\n","    loss = AverageMeter()\n","    model.train()\n","    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n","    for batch_idx, (data, target) in enumerate(tk0):\n","        data, target = data.to(device), target.to(device)  \n","        output = model(data) \n","        loss_this = F.cross_entropy(output, target)\n","        optimizer.zero_grad()\n","        loss_this.backward()\n","        optimizer.step()\n","        loss.update(loss_this.item(), target.shape[0])\n","    print('Train: Average loss: {:.4f}\\n'.format(loss.avg))\n","#torch.save(model.state_dict(),'data/weights_resnet.pth')"],"metadata":{"id":"HfCeHN7sIG5x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset\n","from PIL import Image\n","from torchvision import transforms, datasets\n","class EXCV10TestImageFolder(datasets.ImageFolder):\n","    def __init__(self, *args, **kwargs):\n","        super(EXCV10TestImageFolder, self).__init__(*args, **kwargs)\n","        \n","    def __getitem__(self, index):\n","        img_path = self.imgs[index][0]\n","        pic = Image.open(img_path).convert(\"RGB\")\n","        if self.transform is not None:\n","            img = self.transform(pic)\n","        return img\n","\n","# Vanilla image transform\n","image_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","    \n","# Dataset\n","test_data = EXCV10TestImageFolder('val/', transform=image_transform)\n","\n","# Data loader\n","from torch.utils.data import DataLoader\n","test_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"],"metadata":{"id":"lMbIHYV2IUzq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test CNN\n","def test_cnn(model, test_loader):    \n","    #from ca_utils import ResNet, BasicBlock\n","\n","    pred_arr = []\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for data in test_loader:          \n","\n","          img = data\n","          img = img.to(device)\n","          output = model(img)\n","\n","          _, predict_result = torch.max(output.data, dim=1)  \n","          predict_result = output.argmax(dim=1, keepdim=True)\n","          predict_result = predict_result.cpu().numpy().flatten()\n","          for predict in predict_result:\n","            pred_arr.append(predict)   \n","    return np.array(pred_arr)"],"metadata":{"id":"gaGpijgJIWmF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Face Mask Detection"],"metadata":{"id":"2nl6wFViIZS8"}},{"cell_type":"code","source":["# Dataset\n","import os, glob\n","from PIL import Image\n","from torch.utils.data import Dataset\n","class MaskedFaceTestDataset(Dataset):\n","    def __init__(self, root, transform=None):\n","        super(MaskedFaceTestDataset, self).__init__()\n","        self.imgs = sorted(glob.glob(os.path.join(root, '*.png')))\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        img_path = self.imgs[index]\n","        img = Image.open(img_path).convert(\"RGB\")\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img\n","\n","    def __len__(self):\n","        return len(self.imgs)"],"metadata":{"id":"en7Dr3fmIcHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_masks(test_dataset):\n","    \n","    import torch\n","    import torchvision    \n","    import torchvision.transforms as transforms\n","    from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","    num_classes = 4\n","    with_mask = 0\n","    without_mask = 0\n","    incorrect_mask= 0\n","    mask_list=[]\n","    output_list=[]\n","\n","    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n","    \n","    \"\"\" Download the  model 'face_model.pth' from google drive \"\"\"\n","    !pip install -U --no-cache-dir gdown --pre\n","    !gdown --id 1viTuPLNtB5fMhTrk9Pg_YD0N3jyD-TY_\n","\n","    model.load_state_dict(torch.load('face_model.pth',map_location=torch.device('cpu')))    \n","    model = model.cpu()\n","    model.eval()  \n","\n","    for i in range(len(test_dataset)):\n","        img= test_dataset[i]\n","\n","        with torch.no_grad():\n","            predictions = model([img])\n","\n","        keep_boxes   = torchvision.ops.nms(predictions[0]['boxes'].cpu(),predictions[0]['scores'].cpu(),0.3)\n","        score_filter = predictions[0]['scores'].cpu().numpy()[keep_boxes] > 0.8\n","        test_labels  = predictions[0]['labels'].cpu().numpy()[keep_boxes][score_filter]\n","\n","        without_mask   += np.count_nonzero(test_labels == 1)\n","        with_mask      += np.count_nonzero(test_labels == 2)        \n","        incorrect_mask += np.count_nonzero(test_labels == 3)\n","\n","        mask_list=[with_mask,without_mask,incorrect_mask]\n","        output_list.append(mask_list)\n","    return np.array(output_list, dtype=np.int64)"],"metadata":{"id":"lyWa7-SZIdwv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ResNet(block=BasicBlock, layers=[1, 1, 1], num_classes=10)\n","cp = torch.load(\"data/weights_resnet.pth\", map_location=torch.device(\"cpu\"))\n","model.load_state_dict(cp)\n","\n","output = test_cnn(model, test_loader)\n","output_2 = count_masks(test_data)"],"metadata":{"id":"l9sRGu29JBId"},"execution_count":null,"outputs":[]}]}